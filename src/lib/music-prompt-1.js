`## Master API Prompt for Chord-Based Song Generation

**Objective:** Generate a complete and compelling musical composition (song) based on a user-provided chord progression.

**Input (User-Provided):**

*   **Chord Progression:** A sequence of chords represented in standard chord notation (e.g., Cmaj7, Am, F, G7, Ebdim). The user can specify the number of repetitions of the progression (e.g., loop 4 times).
*   **Genre (Optional):** A musical genre or style (e.g., Pop, Jazz, Rock, Classical, Electronic, Hip-Hop, Blues, Country, Latin). If not provided, the model should select a suitable genre based on the chord progression.
*   **Tempo (Optional):** Beats per minute (BPM). If not provided, the model should infer a suitable tempo based on the genre and chord progression.
*   **Key (Optional):** The tonal center of the song. If not provided, the model should infer the key from the chord progression.
*   **Song Length (Optional):** Desired duration in measures or seconds. If not provided, the model should generate a song of reasonable length (e.g., 2-4 minutes).
*   **Instrumentation (Optional):** A list of desired instruments (e.g., piano, drums, bass, acoustic guitar, strings, synth). If not provided, the model should choose appropriate instrumentation based on the genre.
*   **Mood/Emotion (Optional):** A descriptive word or phrase indicating the desired mood or emotion (e.g., happy, sad, energetic, melancholic, peaceful). This can be used to influence melodic and harmonic choices.

**Output (API Response):**

A structured data object containing the following elements:

*   **MIDI Data:** A standard MIDI file (.mid) representing the complete song. This is the primary output for playback and further editing in music software.
*   **Audio Preview (Optional):** An audio file (.wav or .mp3) generated by the model, providing a quick preview of the song. This could be generated using a default set of virtual instruments.
*   **Musical Score (Optional):** A representation of the song in standard musical notation (e.g., MusicXML).
*   **Song Structure Analysis:**
    *   **Sections:** Identification of song sections (e.g., Intro, Verse 1, Chorus, Verse 2, Bridge, Outro).
    *   **Form:** Description of the overall song form (e.g., AABA, ABABCB).
*   **Metadata:**
    *   **Generated Genre:** The genre chosen by the model (if not provided by the user).
    *   **Generated Tempo:** The tempo chosen by the model (if not provided by the user).
    *   **Generated Key:** The key chosen by the model (if not provided by the user).
    *   **Instrumentation Used:** A list of instruments used in the generated song.

**API Request Example (JSON):**

{
  "chord_progression": ["Am", "G", "C", "F"],
  "genre": "Pop",
  "tempo": 120,
  "instrumentation": ["piano", "drums", "bass", "electric guitar"],
  "mood": "uplifting"
}`